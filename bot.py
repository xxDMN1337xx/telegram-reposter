import asyncio
import os
import re
import pymorphy2
import g4f
from telethon import TelegramClient, events
from telethon.tl.types import Message, PeerChannel
from telethon.utils import get_display_text
from config import API_ID, API_HASH, SESSION_NAME

# === –ö–∞–Ω–∞–ª—ã
CHANNEL_GOOD = 'https://t.me/fbeed1337'
CHANNEL_TRASH = 'https://t.me/musoradsxx'

# === –ü—Ä–æ–≤–∞–π–¥–µ—Ä—ã
fallback_providers = [
    g4f.Provider.AnyProvider,
    g4f.Provider.Blackbox,
    g4f.Provider.Chatai,
    g4f.Provider.CohereForAI_C4AI_Command,
    g4f.Provider.Copilot,
    g4f.Provider.CopilotAccount,
    g4f.Provider.Free2GPT,
    g4f.Provider.Qwen_Qwen_2_5,
    g4f.Provider.Qwen_Qwen_2_5_Max,
    g4f.Provider.Qwen_Qwen_2_72B,
    g4f.Provider.TeachAnything,
    g4f.Provider.WeWordle,
    g4f.Provider.Yqcloud,
]

# === –û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞
def sanitize_input(text):
    text = re.sub(r'https?://\S+', '[—Å—Å—ã–ª–∫–∞]', text)
    text = re.sub(r'[^\w–∞-—è–ê-–Ø—ë–Å.,:;!?%()\-‚Äì‚Äî\n ]+', '', text)
    return text.strip()[:2000]

# === –õ–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è
filter_words = set()
morph = pymorphy2.MorphAnalyzer(lang='ru')

def load_filter_words():
    global filter_words
    if os.path.exists('filter_words.txt'):
        with open('filter_words.txt', 'r', encoding='utf-8') as f:
            filter_words.clear()
            for line in f:
                word = line.strip().lower()
                if word:
                    lemma = morph.parse(word)[0].normal_form
                    filter_words.add(lemma)

def normalize_text(text):
    words = text.lower().split()
    return {morph.parse(word)[0].normal_form for word in words}

# === GPT —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è
async def check_with_gpt(text: str, client) -> str:
    clean_text = sanitize_input(text.replace('"', "'").replace("\n", " "))

    prompt = (
        "–¢—ã –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç, –ø–æ–º–æ–≥–∞—é—â–∏–π –æ—Ç–±–∏—Ä–∞—Ç—å –ø–æ—Å—Ç—ã –¥–ª—è Telegram-–∫–∞–Ω–∞–ª–∞ –ø–æ –∞—Ä–±–∏—Ç—Ä–∞–∂—É —Ç—Ä–∞—Ñ–∏–∫–∞.\n\n"
        "–¢–µ–±–µ –ù–ï–õ–¨–ó–Ø –¥–æ–ø—É—Å–∫–∞—Ç—å –∫ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ —Å–ª–µ–¥—É—é—â–∏–µ —Ç–∏–ø—ã –ø–æ—Å—Ç–æ–≤:\n"
        "- –ª–∏—á–Ω—ã–µ –ø–æ—Å—Ç—ã (–æ –∂–∏–∑–Ω–∏, –º–æ—Ç–∏–≤–∞—Ü–∏–∏, –ø–æ–≥–æ–¥–µ, –º–Ω–µ–Ω–∏—è, —Ä–∞–∑–º—ã—à–ª–µ–Ω–∏—è, —Ñ–∏–ª–æ—Å–æ—Ñ–∏—è)\n"
        "- –æ–±—â–∞—è —Ä–µ–∫–ª–∞–º–∞ –∏ –Ω–µ—Ü–µ–ª–µ–≤—ã–µ –æ—Ñ—Ñ–µ—Ä—ã\n"
        "- –ª—é–±—ã–µ –±–µ—Å–ø–æ–ª–µ–∑–Ω—ã–µ –∏ –Ω–∏ –æ —á—ë–º —Ç–µ–∫—Å—Ç—ã, –±–µ–∑ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –¥–µ–π—Å—Ç–≤–∏–π, —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∏–ª–∏ –¥–∞–Ω–Ω—ã—Ö\n"
        "- –∏–Ω—Ç–µ—Ä–≤—å—é, –ø–æ–¥–∫–∞—Å—Ç—ã, –±–µ—Å–µ–¥—ã, –≤–∏–¥–µ–æ–∏–Ω—Ç–µ—Ä–≤—å—é\n"
        "- —Ä–æ–∑—ã–≥—Ä—ã—à–∏, –∫–æ–Ω–∫—É—Ä—Å—ã, –ø—Ä–∏–∑—ã, –ø–æ–¥–∞—Ä–∫–∏\n"
        "- –ø–æ—Å—Ç—ã –ø—Ä–æ –≤–µ—á–µ—Ä–∏–Ω–∫–∏, –∫–æ–Ω—Ñ–µ—Ä–µ–Ω—Ü–∏–∏, —Å–æ–±—Ä–∞–Ω–∏—è, –º–∏—Ç–∞–ø—ã, —Ç—É—Å–æ–≤–∫–∏ –∏ —Å—Ö–æ–¥–∫–∏\n"
        "- –ª–æ–Ω–≥—Ä–∏–¥—ã –∏–ª–∏ –∫–æ–ª–æ–Ω–∫–∏ –±–µ–∑ –∫–æ–Ω–∫—Ä–µ—Ç–∏–∫–∏: –±–µ–∑ —Å–≤—è–∑–æ–∫, –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤, —Ü–∏—Ñ—Ä –∏–ª–∏ –∫–µ–π—Å–æ–≤\n"
        "- –∂–∞–ª–æ–±—ã, –Ω–∞–±–ª—é–¥–µ–Ω–∏—è, –∏—Å—Ç–æ—Ä–∏—è —Ä–∞–∑–≤–∏—Ç–∏—è —Ä—ã–Ω–∫–∞, ¬´—ç–≤–æ–ª—é—Ü–∏—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞¬ª –∏ —Ç.–¥.\n\n"
        "–ü—É–±–ª–∏–∫–æ–≤–∞—Ç—å –º–æ–∂–Ω–æ –¢–û–õ–¨–ö–û –µ—Å–ª–∏ –ø–æ—Å—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç:\n"
        "- –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É—é –ø–æ–ª—å–∑—É –¥–ª—è –∞—Ä–±–∏—Ç—Ä–∞–∂–Ω–∏–∫–æ–≤: –∫–µ–π—Å—ã, —Å—Ö–µ–º—ã, –∏–Ω—Å–∞–π—Ç—ã, —Ü–∏—Ñ—Ä—ã, —Å–æ–≤–µ—Ç—ã, —Ç–∞–±–ª–∏—Ü—ã\n"
        "- –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Å–≤—è–∑–∫–∏, –∏—Å—Ç–æ—á–Ω–∏–∫–∏ —Ç—Ä–∞—Ñ–∏–∫–∞, –ø–æ–¥—Ö–æ–¥—ã, –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã, —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –æ—Ñ—Ñ–µ—Ä–æ–≤\n"
        "- –ø–æ–ª–µ–∑–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã, —Å–ø–∞–π, –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—é, API, —Å–∫—Ä–∏–ø—Ç—ã, –ø–∞—Ä—Å–µ—Ä—ã, –Ω–∞—Å—Ç—Ä–æ–π–∫–∏\n"
        "- –æ–±–∑–æ—Ä—ã –∏–ª–∏ –Ω–æ–≤–æ—Å—Ç–∏ –æ–± –ò–ò-–∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞—Ö (SkyReels, Scira, Sora, ChatGPT, MidJourney, Runway –∏ —Ç.–¥.)\n"
        "- –Ω–æ–≤–æ—Å—Ç–∏ –ø–æ –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞–º, —Ç—Ä–µ–∫–µ—Ä–∞–º, –±–∞–Ω–∞–º, –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è–º, –ø–ª–∞—Ç—ë–∂–∫–∞–º –∏ —Ç.–¥.\n\n"
        "–ï—Å–ª–∏ –≤ —Ç–µ–∫—Å—Ç–µ –Ω–µ—Ç –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –ø–æ–ª—å–∑—ã ‚Äî —Å—á–∏—Ç–∞–π –µ–≥–æ –±–µ—Å–ø–æ–ª–µ–∑–Ω—ã–º.\n"
        "–ù–µ –±—É–¥—å –º—è–≥–∫–∏–º. –û—Ç—Å–µ–∏–≤–∞–π –≤—Å—ë, —á—Ç–æ –Ω–µ –¥–∞—Å—Ç –≤—ã–≥–æ–¥—ã –∞—Ä–±–∏—Ç—Ä–∞–∂–Ω–∏–∫—É.\n\n"
        f"–ê–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ç–µ–∫—Å—Ç –ø–æ—Å—Ç–∞:\n\"{clean_text}\"\n\n"
        "–û—Ç–≤–µ—Ç—å **–æ–¥–Ω–∏–º —Å–ª–æ–≤–æ–º**, –≤—ã–±–µ—Ä–∏ —Ç–æ–ª—å–∫–æ –∏–∑: —Ä–µ–∫–ª–∞–º–∞, –±–µ—Å–ø–æ–ª–µ–∑–Ω–æ, –ø–æ–ª–µ–∑–Ω–æ."
    )

    summary = {"–ø–æ–ª–µ–∑–Ω–æ": 0, "—Ä–µ–∫–ª–∞–º–∞": 0, "–±–µ—Å–ø–æ–ª–µ–∑–Ω–æ": 0}
    total = len(fallback_providers)

    async def call_provider(provider, index):
        try:
            response = await asyncio.wait_for(
                asyncio.to_thread(
                    g4f.ChatCompletion.create,
                    provider=provider,
                    model=g4f.models.default,
                    messages=[{"role": "user", "content": prompt}]
                ),
                timeout=30
            )
            result = (response or "").strip().lower()
            result = re.sub(r'[^–∞-—è–ê-–Ø]', '', result)
            if result in summary:
                await client.send_message(CHANNEL_TRASH, f"{index+1}/{total} ‚úÖ {provider.__name__}: {result}")
                return result
            await client.send_message(CHANNEL_TRASH, f"{index+1}/{total} ‚ö†Ô∏è {provider.__name__} —Å—Ç—Ä–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç: {result}")
        except Exception as e:
            await client.send_message(CHANNEL_TRASH, f"{index+1}/{total} ‚ùå {provider.__name__} –æ—à–∏–±–∫–∞: {str(e)[:100]}")
        return None

    results = await asyncio.gather(*[call_provider(p, i) for i, p in enumerate(fallback_providers)])

    for r in results:
        if r in summary:
            summary[r] += 1

    total_valid = sum(summary.values())
    if total_valid == 0:
        await client.send_message(CHANNEL_TRASH, "‚ùå –ù–∏ –æ–¥–∏–Ω GPT-–ø—Ä–æ–≤–∞–π–¥–µ—Ä –Ω–µ –¥–∞–ª –æ—Ç–≤–µ—Ç. –ü–æ–≤—Ç–æ—Ä —á–µ—Ä–µ–∑ 30 –º–∏–Ω—É—Ç.")
        await asyncio.sleep(1800)
        return await check_with_gpt(text, client)

    await client.send_message(CHANNEL_TRASH, f"üìä –°–≤–æ–¥–∫–∞: {summary}")
    return "–ø–æ–ª–µ–∑–Ω–æ" if summary["–ø–æ–ª–µ–∑–Ω–æ"] > (summary["—Ä–µ–∫–ª–∞–º–∞"] + summary["–±–µ—Å–ø–æ–ª–µ–∑–Ω–æ"]) else "–º—É—Å–æ—Ä"

# === –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏–π
async def handle_message(event, client):
    load_filter_words()

    # –¢–æ–ª—å–∫–æ –∫–∞–Ω–∞–ª—ã (–∏—Å–∫–ª—é—á–∞–µ–º —á–∞—Ç—ã –∏ –∫–æ–Ω—Ç–∞–∫—Ç—ã)
    if not isinstance(event.message.to_id, PeerChannel):
        return

    if event.poll or event.voice or event.video_note:
        return

    message_text = event.message.text or ""
    if not message_text.strip():
        return

    normalized = normalize_text(message_text)
    if filter_words.intersection(normalized):
        return

    result = await check_with_gpt(message_text, client)

    messages_to_forward = [event.message]
    if event.message.grouped_id:
        async for msg in client.iter_messages(event.chat_id, min_id=event.message.id - 10, max_id=event.message.id + 10):
            if msg.grouped_id == event.message.grouped_id and msg.id != event.message.id:
                messages_to_forward.append(msg)
    messages_to_forward.sort(key=lambda m: m.id)

    # === –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∞
    source = ""
    if event.message.fwd_from and getattr(event.message.fwd_from.from_id, 'channel_id', None):
        try:
            entity = await client.get_entity(PeerChannel(event.message.fwd_from.from_id.channel_id))
            source = f"–ò—Å—Ç–æ—á–Ω–∏–∫: https://t.me/{entity.username}" if entity.username else f"–ò—Å—Ç–æ—á–Ω–∏–∫: {entity.title} {entity.id}"
        except:
            source = f"–ò—Å—Ç–æ—á–Ω–∏–∫: –∫–∞–Ω–∞–ª {event.message.fwd_from.from_id.channel_id}"
    else:
        try:
            entity = await client.get_entity(event.chat_id)
            source = f"–ò—Å—Ç–æ—á–Ω–∏–∫: https://t.me/{entity.username}" if entity.username else f"–ò—Å—Ç–æ—á–Ω–∏–∫: {entity.title} {entity.id}"
        except:
            source = f"–ò—Å—Ç–æ—á–Ω–∏–∫: –∫–∞–Ω–∞–ª {event.chat_id}"

    target_channel = CHANNEL_GOOD if result == "–ø–æ–ª–µ–∑–Ω–æ" else CHANNEL_TRASH

    text_buffer = ""
    media = []

    for msg in messages_to_forward:
        if msg.message:
            formatted = get_display_text(msg)
            text_buffer += formatted.strip() + "\n"
        if msg.media:
            media.append(msg.media)

    text_buffer = text_buffer.strip()
    max_text_len = 1000 if media else 4000
    chunks = [text_buffer[i:i+max_text_len] for i in range(0, len(text_buffer), max_text_len)]
    if chunks:
        chunks[-1] += f"\n\n{source}"

    try:
        if media:
            await client.send_file(target_channel, file=media, caption=chunks[0], force_document=False, parse_mode='Markdown')
            for part in chunks[1:]:
                await client.send_message(target_channel, part, parse_mode='Markdown')
        else:
            for part in chunks:
                await client.send_message(target_channel, part, parse_mode='Markdown')
    except Exception as e:
        print(f"[!] –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ: {e}")

    print(f"[OK] –ö–æ–ø–∏—è —Å –∏—Å—Ç–æ—á–Ω–∏–∫–∞: {source}")

# === –ó–∞–ø—É—Å–∫ –∫–ª–∏–µ–Ω—Ç–∞
async def main():
    client = TelegramClient(SESSION_NAME, API_ID, API_HASH)
    await client.start()

    @client.on(events.NewMessage(incoming=True))
    async def handler(event):
        await handle_message(event, client)

    await client.run_until_disconnected()

if __name__ == "__main__":
    asyncio.run(main())
