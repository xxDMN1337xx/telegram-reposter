import asyncio
import os
import re
import pymorphy2
import g4f
from telethon import TelegramClient, events
from telethon.tl.types import Message
from config import API_ID, API_HASH, SESSION_NAME

# === –ö–∞–Ω–∞–ª—ã
CHANNEL_GOOD = 'https://t.me/fbeed1337'
CHANNEL_TRASH = 'https://t.me/musoradsxx'

# === –ü—Ä–æ–≤–∞–π–¥–µ—Ä—ã
fallback_providers = [
    g4f.Provider.AnyProvider,
    g4f.Provider.Blackbox,
    g4f.Provider.Chatai,
    g4f.Provider.CohereForAI_C4AI_Command,
    g4f.Provider.Copilot,
    g4f.Provider.CopilotAccount,
    g4f.Provider.Free2GPT,
    g4f.Provider.Qwen_Qwen_2_5,
    g4f.Provider.Qwen_Qwen_2_5_Max,
    g4f.Provider.Qwen_Qwen_2_72B,
    g4f.Provider.TeachAnything,
    g4f.Provider.WeWordle,
    g4f.Provider.Yqcloud,
]

MAX_LEN = 4096  # Telegram –ª–∏–º–∏—Ç –Ω–∞ –æ–¥–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ
CAPTION_LEN = 1024  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä caption –¥–ª—è –º–µ–¥–∏–∞
SPLIT_LEN = 4000  # –Ω–µ–º–Ω–æ–≥–æ –º–µ–Ω—å—à–µ, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –æ—à–∏–±–æ–∫ –ø–æ —Å–ª–æ–≤–∞–º/—é–Ω–∏–∫–æ–¥—É

# --- –≠–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ MarkdownV2 ---
def escape_markdown_v2(text):
    # https://core.telegram.org/bots/api#markdownv2-style
    symbols = r'_ * [ ] ( ) ~ ` > # + - = | { } . !'.split()
    for s in symbols:
        text = text.replace(s, '\\' + s)
    return text

def sanitize_input(text):
    text = re.sub(r'https?://\S+', '[—Å—Å—ã–ª–∫–∞]', text)
    text = re.sub(r'[^\w–∞-—è–ê-–Ø—ë–Å.,:;!?%()\-‚Äì‚Äî\n ]+', '', text)
    return text.strip()[:2000]

filter_words = set()
morph = pymorphy2.MorphAnalyzer(lang='ru')

def load_filter_words():
    global filter_words
    if os.path.exists('filter_words.txt'):
        with open('filter_words.txt', 'r', encoding='utf-8') as f:
            filter_words.clear()
            for line in f:
                word = line.strip().lower()
                if word:
                    lemma = morph.parse(word)[0].normal_form
                    filter_words.add(lemma)

def normalize_text(text):
    words = text.lower().split()
    return {morph.parse(word)[0].normal_form for word in words}

def split_text(text, max_len=SPLIT_LEN):
    parts = []
    while len(text) > max_len:
        idx = text.rfind('\n', 0, max_len)
        if idx == -1:
            idx = max_len
        parts.append(text[:idx].strip())
        text = text[idx:].lstrip()
    if text:
        parts.append(text)
    return parts

def split_caption_and_text(full_text, caption_len=CAPTION_LEN, split_len=SPLIT_LEN):
    if len(full_text) <= caption_len:
        return full_text, []
    caption = full_text[:caption_len]
    rest = full_text[caption_len:]
    parts = split_text(rest, split_len)
    return caption, parts

async def check_with_gpt(text: str, client) -> str:
    clean_text = sanitize_input(text.replace('"', "'").replace("\n", " "))

    prompt = (
        "–¢—ã –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç, –ø–æ–º–æ–≥–∞—é—â–∏–π –æ—Ç–±–∏—Ä–∞—Ç—å –ø–æ—Å—Ç—ã –¥–ª—è Telegram-–∫–∞–Ω–∞–ª–∞ –ø–æ –∞—Ä–±–∏—Ç—Ä–∞–∂—É —Ç—Ä–∞—Ñ–∏–∫–∞.\n\n"
        "–¢–µ–±–µ –ù–ï–õ–¨–ó–Ø –¥–æ–ø—É—Å–∫–∞—Ç—å –∫ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ —Å–ª–µ–¥—É—é—â–∏–µ —Ç–∏–ø—ã –ø–æ—Å—Ç–æ–≤:\n"
        "- –ª–∏—á–Ω—ã–µ –ø–æ—Å—Ç—ã (–æ –∂–∏–∑–Ω–∏, –º–æ—Ç–∏–≤–∞—Ü–∏–∏, –ø–æ–≥–æ–¥–µ, –º–Ω–µ–Ω–∏—è, —Ä–∞–∑–º—ã—à–ª–µ–Ω–∏—è, —Ñ–∏–ª–æ—Å–æ—Ñ–∏—è)\n"
        "- –æ–±—â–∞—è —Ä–µ–∫–ª–∞–º–∞ –∏ –Ω–µ—Ü–µ–ª–µ–≤—ã–µ –æ—Ñ—Ñ–µ—Ä—ã\n"
        "- –ª—é–±—ã–µ –±–µ—Å–ø–æ–ª–µ–∑–Ω—ã–µ –∏ –Ω–∏ –æ —á—ë–º —Ç–µ–∫—Å—Ç—ã, –±–µ–∑ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –¥–µ–π—Å—Ç–≤–∏–π, —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∏–ª–∏ –¥–∞–Ω–Ω—ã—Ö\n"
        "- –∏–Ω—Ç–µ—Ä–≤—å—é, –ø–æ–¥–∫–∞—Å—Ç—ã, –±–µ—Å–µ–¥—ã, –≤–∏–¥–µ–æ–∏–Ω—Ç–µ—Ä–≤—å—é\n"
        "- —Ä–æ–∑—ã–≥—Ä—ã—à–∏, –∫–æ–Ω–∫—É—Ä—Å—ã, –ø—Ä–∏–∑—ã, –ø–æ–¥–∞—Ä–∫–∏\n"
        "- –ø–æ—Å—Ç—ã –ø—Ä–æ –≤–µ—á–µ—Ä–∏–Ω–∫–∏, –∫–æ–Ω—Ñ–µ—Ä–µ–Ω—Ü–∏–∏, —Å–æ–±—Ä–∞–Ω–∏—è, –º–∏—Ç–∞–ø—ã, —Ç—É—Å–æ–≤–∫–∏ –∏ —Å—Ö–æ–¥–∫–∏\n"
        "- –ª–æ–Ω–≥—Ä–∏–¥—ã –∏–ª–∏ –∫–æ–ª–æ–Ω–∫–∏ –±–µ–∑ –∫–æ–Ω–∫—Ä–µ—Ç–∏–∫–∏: –±–µ–∑ —Å–≤—è–∑–æ–∫, –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤, —Ü–∏—Ñ—Ä –∏–ª–∏ –∫–µ–π—Å–æ–≤\n"
        "- –∂–∞–ª–æ–±—ã, –Ω–∞–±–ª—é–¥–µ–Ω–∏—è, –∏—Å—Ç–æ—Ä–∏—è —Ä–∞–∑–≤–∏—Ç–∏—è —Ä—ã–Ω–∫–∞, ¬´—ç–≤–æ–ª—é—Ü–∏—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞¬ª –∏ —Ç.–¥.\n\n"
        "–ü—É–±–ª–∏–∫–æ–≤–∞—Ç—å –º–æ–∂–Ω–æ –¢–û–õ–¨–ö–û –µ—Å–ª–∏ –ø–æ—Å—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç:\n"
        "- –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É—é –ø–æ–ª—å–∑—É –¥–ª—è –∞—Ä–±–∏—Ç—Ä–∞–∂–Ω–∏–∫–æ–≤: –∫–µ–π—Å—ã, —Å—Ö–µ–º—ã, –∏–Ω—Å–∞–π—Ç—ã, —Ü–∏—Ñ—Ä—ã, —Å–æ–≤–µ—Ç—ã, —Ç–∞–±–ª–∏—Ü—ã\n"
        "- –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Å–≤—è–∑–∫–∏, –∏—Å—Ç–æ—á–Ω–∏–∫–∏ —Ç—Ä–∞—Ñ–∏–∫–∞, –ø–æ–¥—Ö–æ–¥—ã, –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã, —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –æ—Ñ—Ñ–µ—Ä–æ–≤\n"
        "- –ø–æ–ª–µ–∑–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã, —Å–ø–∞–π, –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—é, API, —Å–∫—Ä–∏–ø—Ç—ã, –ø–∞—Ä—Å–µ—Ä—ã, –Ω–∞—Å—Ç—Ä–æ–π–∫–∏\n"
        "- –æ–±–∑–æ—Ä—ã –∏–ª–∏ –Ω–æ–≤–æ—Å—Ç–∏ –æ–± –ò–ò-–∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞—Ö (SkyReels, Scira, Sora, ChatGPT, MidJourney, Runway –∏ —Ç.–¥.)\n"
        "- –Ω–æ–≤–æ—Å—Ç–∏ –ø–æ –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞–º, —Ç—Ä–µ–∫–µ—Ä–∞–º, –±–∞–Ω–∞–º, –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è–º, –ø–ª–∞—Ç—ë–∂–∫–∞–º –∏ —Ç.–¥.\n\n"
        "–ï—Å–ª–∏ –≤ —Ç–µ–∫—Å—Ç–µ –Ω–µ—Ç –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –ø–æ–ª—å–∑—ã ‚Äî —Å—á–∏—Ç–∞–π –µ–≥–æ –±–µ—Å–ø–æ–ª–µ–∑–Ω—ã–º.\n"
        "–ù–µ –±—É–¥—å –º—è–≥–∫–∏–º. –û—Ç—Å–µ–∏–≤–∞–π –≤—Å—ë, —á—Ç–æ –Ω–µ –¥–∞—Å—Ç –≤—ã–≥–æ–¥—ã –∞—Ä–±–∏—Ç—Ä–∞–∂–Ω–∏–∫—É.\n\n"
        f"–ê–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ç–µ–∫—Å—Ç –ø–æ—Å—Ç–∞:\n\"{clean_text}\"\n\n"
        "–û—Ç–≤–µ—Ç—å **–æ–¥–Ω–∏–º —Å–ª–æ–≤–æ–º**, –≤—ã–±–µ—Ä–∏ —Ç–æ–ª—å–∫–æ –∏–∑: —Ä–µ–∫–ª–∞–º–∞, –±–µ—Å–ø–æ–ª–µ–∑–Ω–æ, –ø–æ–ª–µ–∑–Ω–æ."
    )

    results = []
    total = len(fallback_providers)

    async def call_provider(provider, index):
        try:
            model = getattr(provider, "models", ["gpt-3.5"])[0]
            response = await asyncio.wait_for(
                asyncio.to_thread(
                    g4f.ChatCompletion.create,
                    provider=provider,
                    model=model,
                    messages=[{"role": "user", "content": prompt}]
                ),
                timeout=30
            )
            result = (response or "").strip().lower()
            result = re.sub(r'[^–∞-—è–ê-–Ø]', '', result)
            if result in ['—Ä–µ–∫–ª–∞–º–∞', '–±–µ—Å–ø–æ–ª–µ–∑–Ω–æ', '–ø–æ–ª–µ–∑–Ω–æ']:
                await client.send_message(CHANNEL_TRASH, escape_markdown_v2(f"{index+1}/{total} ‚úÖ {provider.__name__} ({model}): {result}"), parse_mode='MarkdownV2')
                return result
            else:
                await client.send_message(CHANNEL_TRASH, escape_markdown_v2(f"{index+1}/{total} ‚ö†Ô∏è {provider.__name__} —Å—Ç—Ä–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç: '{result}'"), parse_mode='MarkdownV2')
        except Exception as e:
            await client.send_message(CHANNEL_TRASH, escape_markdown_v2(f"{index+1}/{total} ‚ùå {provider.__name__} –æ—à–∏–±–∫–∞: {str(e)[:100]}"), parse_mode='MarkdownV2')
        return None

    tasks = [call_provider(p, i) for i, p in enumerate(fallback_providers)]
    raw_results = await asyncio.gather(*tasks)

    summary = {"–ø–æ–ª–µ–∑–Ω–æ": 0, "—Ä–µ–∫–ª–∞–º–∞": 0, "–±–µ—Å–ø–æ–ª–µ–∑–Ω–æ": 0}
    for result in raw_results:
        if result in summary:
            summary[result] += 1

    total_valid = sum(summary.values())

    if total_valid == 0:
        await client.send_message(CHANNEL_TRASH, escape_markdown_v2("‚ùå –ù–∏ –æ–¥–∏–Ω GPT-–ø—Ä–æ–≤–∞–π–¥–µ—Ä –Ω–µ –¥–∞–ª –æ—Ç–≤–µ—Ç. –ü–æ–≤—Ç–æ—Ä —á–µ—Ä–µ–∑ 30 –º–∏–Ω—É—Ç."), parse_mode='MarkdownV2')
        await asyncio.sleep(1800)
        return await check_with_gpt(text, client)

    await client.send_message(CHANNEL_TRASH, escape_markdown_v2(f"üìä –°–≤–æ–¥–∫–∞: {summary}"), parse_mode='MarkdownV2')

    if summary["–ø–æ–ª–µ–∑–Ω–æ"] > (summary["—Ä–µ–∫–ª–∞–º–∞"] + summary["–±–µ—Å–ø–æ–ª–µ–∑–Ω–æ"]):
        return "–ø–æ–ª–µ–∑–Ω–æ"
    else:
        return "–º—É—Å–æ—Ä"

async def handle_message(event, client):
    # –¢–æ–ª—å–∫–æ –¥–ª—è –∫–∞–Ω–∞–ª–æ–≤ (—á–∞—Ç—ã, —Å—É–ø–µ—Ä–≥—Ä—É–ø–ø—ã –∏ –ª–∏—á–∫–∏ –∏–≥–Ω–æ—Ä–∏—Ä—É—é—Ç—Å—è)
    if not getattr(event, "is_channel", False):
        return

    load_filter_words()

    if event.poll or event.voice or event.video_note:
        return

    message_text = event.message.text or ""
    if not message_text.strip():
        return

    if len(message_text) > 2000:
        await client.send_message(CHANNEL_TRASH, escape_markdown_v2(f"‚ö†Ô∏è –°–æ–æ–±—â–µ–Ω–∏–µ –æ–±—Ä–µ–∑–∞–Ω–æ –¥–æ 2000 —Å–∏–º–≤–æ–ª–æ–≤ (–±—ã–ª–æ {len(message_text)})"), parse_mode='MarkdownV2')

    normalized = normalize_text(message_text)
    if filter_words.intersection(normalized):
        return

    result = await check_with_gpt(message_text, client)

    messages_to_forward = [event.message]
    if event.message.grouped_id:
        async for msg in client.iter_messages(event.chat_id, min_id=event.message.id - 10, max_id=event.message.id + 10):
            if msg.grouped_id == event.message.grouped_id and msg.id != event.message.id:
                messages_to_forward.append(msg)
    messages_to_forward.sort(key=lambda m: m.id)

    # --- –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∞ ---
    if event.message.fwd_from and getattr(event.message.fwd_from.from_id, 'channel_id', None):
        channel_id = event.message.fwd_from.from_id.channel_id
        try:
            orig_chat = await client.get_entity(channel_id)
            if hasattr(orig_chat, "username") and orig_chat.username:
                source_url = f"https://t.me/{orig_chat.username}"
            else:
                source_url = f"–ö–∞–Ω–∞–ª: {getattr(orig_chat, 'title', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è')} (ID: {channel_id})"
        except Exception as e:
            source_url = f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –∫–∞–Ω–∞–ª (ID: {channel_id})"
    else:
        chat = await event.get_chat()
        if hasattr(chat, "username") and chat.username:
            source_url = f"https://t.me/{chat.username}"
        else:
            source_url = f"–ö–∞–Ω–∞–ª: {getattr(chat, 'title', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è')} (ID: {chat.id})"

    target_channel = CHANNEL_GOOD if result == "–ø–æ–ª–µ–∑–Ω–æ" else CHANNEL_TRASH

    media_files = []
    full_text = ""

    for msg in messages_to_forward:
        if msg.media:
            media_files.append(msg.media)
        if msg.text:
            full_text += msg.text.strip() + "\n"

    if full_text.strip():
        text_parts = split_text(full_text.strip(), SPLIT_LEN)
        text_parts[-1] = text_parts[-1] + f"\n\n–ò—Å—Ç–æ—á–Ω–∏–∫: {source_url}"
    else:
        text_parts = [f"–ò—Å—Ç–æ—á–Ω–∏–∫: {source_url}"]

    if media_files:
        caption, rest_parts = split_caption_and_text(text_parts[0], CAPTION_LEN, SPLIT_LEN)
        try:
            await client.send_file(
                target_channel,
                file=media_files,
                caption=escape_markdown_v2(caption),
                force_document=False,
                parse_mode='MarkdownV2'
            )
            for part in rest_parts + text_parts[1:]:
                await client.send_message(target_channel, escape_markdown_v2(part), parse_mode='MarkdownV2')
        except Exception as e:
            print(f"[!] –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –º–µ–¥–∏–∞: {e}")
    else:
        for part in text_parts:
            await client.send_message(target_channel, escape_markdown_v2(part), parse_mode='MarkdownV2')

    print(f"[OK] –ö–æ–ø–∏—è —Å –∏—Å—Ç–æ—á–Ω–∏–∫–∞: {source_url}")

async def main():
    client = TelegramClient(SESSION_NAME, API_ID, API_HASH)
    await client.start()

    @client.on(events.NewMessage(incoming=True))
    async def handler(event):
        await handle_message(event, client)

    await client.run_until_disconnected()

if __name__ == "__main__":
    asyncio.run(main())
