import asyncio
import os
import re
import pymorphy2
import g4f
from telethon import TelegramClient, events
from telethon.tl.types import Message, PeerChannel, PeerUser
from config import API_ID, API_HASH, SESSION_NAME

# === –ö–∞–Ω–∞–ª—ã
CHANNEL_GOOD = 'https://t.me/fbeed1337'
CHANNEL_TRASH = 'https://t.me/musoradsxx'

# === –ü—Ä–æ–≤–∞–π–¥–µ—Ä—ã
fallback_providers = [
    g4f.Provider.Blackbox,
    g4f.Provider.CohereForAI_C4AI_Command,
    g4f.Provider.Free2GPT,
    g4f.Provider.Qwen_Qwen_2_5,
    g4f.Provider.Qwen_Qwen_2_5_Max,
    g4f.Provider.Qwen_Qwen_2_72B,
    g4f.Provider.WeWordle,
    g4f.Provider.Yqcloud,
]

# === –û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞
def sanitize_input(text):
    text = re.sub(r'https?://\S+', '[—Å—Å—ã–ª–∫–∞]', text)
    text = re.sub(r'[^\w–∞-—è–ê-–Ø—ë–Å.,:;!?%()\-‚Äì‚Äî\n ]+', '', text)
    return text.strip()[:2000]

# === –õ–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è
filter_words = set()
morph = pymorphy2.MorphAnalyzer(lang='ru')

def load_filter_words():
    global filter_words
    if os.path.exists('filter_words.txt'):
        with open('filter_words.txt', 'r', encoding='utf-8') as f:
            filter_words.clear()
            for line in f:
                word = line.strip().lower()
                if word:
                    lemma = morph.parse(word)[0].normal_form
                    filter_words.add(lemma)

def normalize_text(text):
    words = text.lower().split()
    return {morph.parse(word)[0].normal_form for word in words}

# === HTML —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
def escape_html(text):
    return (text.replace("&", "&amp;")
                .replace("<", "&lt;")
                .replace(">", "&gt;"))

def format_message_to_html(message):
    if not message.entities:
        return escape_html(message.text)

    entities = sorted(message.entities, key=lambda e: e.offset)
    text = message.text
    result = ""
    last_offset = 0

    for entity in entities:
        result += escape_html(text[last_offset:entity.offset])
        segment = escape_html(text[entity.offset:entity.offset + entity.length])

        tag_open, tag_close = '', ''
        etype = type(entity).__name__
        if etype == 'MessageEntityBold': tag_open, tag_close = '<b>', '</b>'
        elif etype == 'MessageEntityItalic': tag_open, tag_close = '<i>', '</i>'
        elif etype == 'MessageEntityUnderline': tag_open, tag_close = '<u>', '</u>'
        elif etype == 'MessageEntityStrike': tag_open, tag_close = '<s>', '</s>'
        elif etype == 'MessageEntitySpoiler': tag_open, tag_close = '<span class="tg-spoiler">', '</span>'
        elif etype == 'MessageEntityUrl': tag_open, tag_close = f'<a href="{segment}">', '</a>'
        elif etype == 'MessageEntityTextUrl': tag_open, tag_close = f'<a href="{entity.url}">', '</a>'
        elif etype == 'MessageEntityMentionName': tag_open, tag_close = f'<a href="tg://user?id={entity.user_id}">', '</a>'
        elif etype == 'MessageEntityCode': tag_open, tag_close = '<code>', '</code>'
        elif etype == 'MessageEntityPre': tag_open, tag_close = '<pre>', '</pre>'
        elif etype == 'MessageEntityQuote': tag_open, tag_close = '<blockquote>', '</blockquote>'

        result += f'{tag_open}{segment}{tag_close}'
        last_offset = entity.offset + entity.length

    result += escape_html(text[last_offset:])
    return result

# === –£–º–Ω–æ–µ —Ä–∞–∑–±–∏–µ–Ω–∏–µ HTML —Ç–µ–∫—Å—Ç–∞
def smart_split_html(html, max_len):
    blocks = re.split(r'(</?(?:b|i|u|s|code|pre|a|span|blockquote)[^>]*>)', html)
    result = []
    buffer = ''

    for block in blocks:
        if len(buffer) + len(block) <= max_len:
            buffer += block
        else:
            if buffer:
                result.append(buffer.strip())
            buffer = block

    if buffer:
        result.append(buffer.strip())
    return result

# === GPT —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è
async def check_with_gpt(text: str, client) -> str:
    clean_text = sanitize_input(text.replace('"', "'").replace("\n", " "))

    prompt = (
        "–¢—ã –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç, –ø–æ–º–æ–≥–∞—é—â–∏–π –æ—Ç–±–∏—Ä–∞—Ç—å –ø–æ—Å—Ç—ã –¥–ª—è Telegram-–∫–∞–Ω–∞–ª–∞ –ø–æ –∞—Ä–±–∏—Ç—Ä–∞–∂—É —Ç—Ä–∞—Ñ–∏–∫–∞.\n\n"
        "[...]\n\n"  # –°–æ–∫—Ä–∞—Ç–∏–ª –¥–ª—è —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏ (–æ—Å—Ç–∞–≤—å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –ø—Ä–æ–º–ø—Ç —É —Å–µ–±—è)
        f"–ê–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ç–µ–∫—Å—Ç –ø–æ—Å—Ç–∞:\n\"{clean_text}\"\n\n"
        "–û—Ç–≤–µ—Ç—å **–æ–¥–Ω–∏–º —Å–ª–æ–≤–æ–º**, –≤—ã–±–µ—Ä–∏ —Ç–æ–ª—å–∫–æ –∏–∑: —Ä–µ–∫–ª–∞–º–∞, –±–µ—Å–ø–æ–ª–µ–∑–Ω–æ, –ø–æ–ª–µ–∑–Ω–æ."
    )

    tasks = []
    for i, provider in enumerate(fallback_providers):
        async def call(provider=provider, i=i):
            try:
                response = await asyncio.wait_for(asyncio.to_thread(g4f.ChatCompletion.create,
                    provider=provider, model=g4f.models.default,
                    messages=[{"role": "user", "content": prompt}]), timeout=30)
                result = (response or '').strip().lower()
                result = re.sub(r'[^–∞-—è–ê-–Ø]', '', result)
                if result in ['—Ä–µ–∫–ª–∞–º–∞', '–±–µ—Å–ø–æ–ª–µ–∑–Ω–æ', '–ø–æ–ª–µ–∑–Ω–æ']:
                    await client.send_message(CHANNEL_TRASH, f"{i+1}/{len(fallback_providers)} ‚úÖ {provider.__name__}: {result}")
                    return result
                await client.send_message(CHANNEL_TRASH, f"{i+1}/{len(fallback_providers)} ‚ö†Ô∏è {provider.__name__}: '{result}'")
            except Exception as e:
                await client.send_message(CHANNEL_TRASH, f"{i+1}/{len(fallback_providers)} ‚ùå {provider.__name__}: {str(e)[:100]}")
            return None
        tasks.append(call())

    raw_results = await asyncio.gather(*tasks)
    summary = {"–ø–æ–ª–µ–∑–Ω–æ": 0, "—Ä–µ–∫–ª–∞–º–∞": 0, "–±–µ—Å–ø–æ–ª–µ–∑–Ω–æ": 0}
    for r in raw_results:
        if r in summary:
            summary[r] += 1

    await client.send_message(CHANNEL_TRASH, f"üìä –°–≤–æ–¥–∫–∞: {summary}")
    if summary['–ø–æ–ª–µ–∑–Ω–æ'] > summary['—Ä–µ–∫–ª–∞–º–∞'] + summary['–±–µ—Å–ø–æ–ª–µ–∑–Ω–æ']:
        return '–ø–æ–ª–µ–∑–Ω–æ'
    return '–º—É—Å–æ—Ä'

# === –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏–π
async def handle_message(event, client):
    load_filter_words()
    if not isinstance(event.message.to_id, PeerChannel): return
    if event.poll or event.voice or event.video_note: return
    if not (event.message.text and event.message.text.strip()): return

    if len(event.message.text) > 2000:
        await client.send_message(CHANNEL_TRASH, f"‚ö†Ô∏è –°–æ–æ–±—â–µ–Ω–∏–µ –æ–±—Ä–µ–∑–∞–Ω–æ –¥–æ 2000 —Å–∏–º–≤–æ–ª–æ–≤ (–±—ã–ª–æ {len(event.message.text)})")

    if filter_words.intersection(normalize_text(event.message.text)):
        return

    result = await check_with_gpt(event.message.text, client)

    messages_to_forward = [event.message]
    if event.message.grouped_id:
        async for msg in client.iter_messages(event.chat_id, min_id=event.message.id - 10, max_id=event.message.id + 10):
            if msg.grouped_id == event.message.grouped_id and msg.id != event.message.id:
                messages_to_forward.append(msg)
    messages_to_forward.sort(key=lambda m: m.id)

    source = ""
    try:
        entity = await client.get_entity(event.chat_id)
        source = f"–ò—Å—Ç–æ—á–Ω–∏–∫: https://t.me/{entity.username}" if entity.username else f"–ò—Å—Ç–æ—á–Ω–∏–∫: {entity.title} {entity.id}"
    except:
        source = f"–ò—Å—Ç–æ—á–Ω–∏–∫: –∫–∞–Ω–∞–ª {event.chat_id}"

    target_channel = CHANNEL_GOOD if result == '–ø–æ–ª–µ–∑–Ω–æ' else CHANNEL_TRASH

    html_buffer = ""
    media = []
    for msg in messages_to_forward:
        if msg.text:
            html_buffer += format_message_to_html(msg).strip() + "\n"
        if msg.media:
            media.append(msg.media)

    html_buffer = html_buffer.strip()
    max_text_len = 1000 if media else 4000
    chunks = smart_split_html(html_buffer, max_text_len)
    if chunks:
        chunks[-1] += f"\n\n{escape_html(source)}"

    if media:
        try:
            await client.send_file(target_channel, file=media, caption=chunks[0], force_document=False, parse_mode='html')
            for part in chunks[1:]:
                await client.send_message(target_channel, part, parse_mode='html')
        except Exception as e:
            print(f"[!] –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –º–µ–¥–∏–∞: {e}")
    else:
        for part in chunks:
            await client.send_message(target_channel, part, parse_mode='html')
    print(f"[OK] –ö–æ–ø–∏—è —Å –∏—Å—Ç–æ—á–Ω–∏–∫–∞: {source}")

# === –ó–∞–ø—É—Å–∫ –∫–ª–∏–µ–Ω—Ç–∞
async def main():
    client = TelegramClient(SESSION_NAME, API_ID, API_HASH)
    await client.start()

    @client.on(events.NewMessage(incoming=True))
    async def handler(event):
        await handle_message(event, client)

    await client.run_until_disconnected()

if __name__ == "__main__":
    asyncio.run(main())
